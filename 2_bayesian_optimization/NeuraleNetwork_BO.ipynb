{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.layers import *\n",
    "from skopt import gp_minimize\n",
    "from skopt.space import Real, Integer, Categorical\n",
    "from skopt.utils import use_named_args\n",
    "from sklearn.model_selection import KFold\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SurfaceData=pd.read_csv('SurfaceData.csv',delimiter=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(SurfaceData)):\n",
    "    SurfaceData[\"bins\"][i]=np.fromstring(SurfaceData[\"bins\"][i][1:-2],sep=',')\n",
    "    SurfaceData[\"n0\"][i]=np.fromstring(SurfaceData[\"n0\"][i][1:-2],sep=',')\n",
    "    SurfaceData[\"Qquerys\"][i]=np.fromstring(SurfaceData[\"Qquerys\"][i][1:-2],sep=',')\n",
    "    SurfaceData[\"PSquerys\"][i]=np.fromstring(SurfaceData[\"PSquerys\"][i][1:-2],sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SurfaceData_Simulated=SurfaceData[SurfaceData[\"DU\"].notna()]#Select labeled surfaces\n",
    "SurfaceData_Simulated=SurfaceData_Simulated[SurfaceData[\"DU\"]>=6]#select fully rough\n",
    "SurfaceData_Pool=SurfaceData[SurfaceData[\"DU\"].isna()]#Transerring unlabeled surfaces in repository\n",
    "ListOfLabledID=SurfaceData_Simulated[\"Surface_ID\"].to_numpy()\n",
    "DUTrain=SurfaceData_Simulated[\"kr\"].to_numpy()#Get labels\n",
    "SurfacePoolID=SurfaceData_Pool[\"Surface_ID\"].to_numpy()\n",
    "\n",
    "Iteration_num=50 # number of NN members\n",
    "SurfaceTrain=[]\n",
    "SurfaceReal=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in ListOfLabledID.astype(int):\n",
    "    SurfaceTrain_row=[SurfaceData.iloc[i].kt/SurfaceData.iloc[i].K_99,SurfaceData.iloc[i].lambda0_k99,SurfaceData.iloc[i].lambda1_k99]\n",
    "    SurfaceTrain_row.extend(SurfaceData.iloc[i].n0)\n",
    "    SurfaceTrain_row.extend(SurfaceData.iloc[i].PSquerys)\n",
    "    SurfaceTrain.append(SurfaceTrain_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "space = [\n",
    "    Integer(1, 256, name='n_neurons_0'),\n",
    "    Integer(1, 256, name='n_neurons_1'),\n",
    "    Integer(1, 256, name='n_neurons_2'),\n",
    "    Categorical(['sigmoid','linear',\"tanh\", 'relu','leakyrelu'], name='activation'),\n",
    "    Real(1e-4, 1e-1, prior='log-uniform', name='lr'),\n",
    "    Real(1e-4, 1e-1, prior='log-uniform', name='regularization')\n",
    "]#Specify to be tuned hyperparameters and the range\n",
    "@use_named_args(dimensions=space)\n",
    "\n",
    "def build_model(**space):\n",
    "    model = keras.Sequential()\n",
    "    # Add input layer; images have one channel (102, 302, 1)\n",
    "    input_shape = 63\n",
    "    if space['activation']=='leakyrelu':\n",
    "        model.add(keras.layers.Dense(int(space['n_neurons_0']),input_shape=(input_shape,),activation=keras.layers.LeakyReLU(alpha=0.1),kernel_regularizer=keras.regularizers.l2(space['regularization'])))\n",
    "    else:\n",
    "        model.add(keras.layers.Dense(int(space['n_neurons_0']),input_shape=(input_shape,),activation=keras.layers.Activation(space['activation']),kernel_regularizer=keras.regularizers.l2(space['regularization'])))\n",
    "    for i in range(2):\n",
    "        model.add(keras.layers.Dense(int(space['n_neurons_'+str(i+1)]),kernel_regularizer=keras.regularizers.l2(space['regularization'])))\n",
    "        if space['activation'] == 'leakyrelu':\n",
    "            model.add(keras.layers.LeakyReLU(alpha=0.1))\n",
    "        else:\n",
    "            model.add(keras.layers.Activation(space['activation']))\n",
    "    # Add output layer\n",
    "    model.add(keras.layers.Dense(1,kernel_regularizer=keras.regularizers.l2(space['regularization'])))\n",
    "    if space['activation'] == 'leakyrelu':\n",
    "        model.add(keras.layers.LeakyReLU(alpha=0.1))\n",
    "    else:\n",
    "        model.add(keras.layers.Activation(space['activation']))\n",
    "    # Compile the model\n",
    "    model.compile(optimizer=keras.optimizers.Adam(space['lr']), loss=keras.losses.MeanSquaredError(),\n",
    "                  metrics=[keras.metrics.MeanSquaredError(),keras.metrics.MeanAbsolutePercentageError(name=\"MAPE\")])\n",
    "    return model\n",
    "def lr_scheduler(epoch, learning_rate):\n",
    "    lr = learning_rate\n",
    "    if epoch == 1000:\n",
    "        learning_rate = lr*0.5\n",
    "        return learning_rate\n",
    "    elif epoch == 1500:\n",
    "        learning_rate = lr*0.5\n",
    "        return learning_rate\n",
    "    elif epoch == 1800:\n",
    "        learning_rate = lr*0.5\n",
    "        return learning_rate\n",
    "    else:\n",
    "        learning_rate = lr\n",
    "        return learning_rate\n",
    "    \n",
    "new_lr = keras.callbacks.LearningRateScheduler(lr_scheduler, verbose=0)\n",
    "def output_val_loss_BO(epoch,logs):\n",
    "    print('the keys are:{}'.format(logs.keys))\n",
    "def objective(space):\n",
    "    kfold=KFold(n_splits=10,shuffle=True)\n",
    "    fold_num=1\n",
    "    val_mse_k_fold=np.zeros(10)\n",
    "    print('Current space')\n",
    "    print(space)\n",
    "    for train_id,val_id in kfold.split(SurfaceTrain,DUTrain):\n",
    "\n",
    "        model = build_model(space)\n",
    "        #start_epoch = time.time()\n",
    "    # ckpt_filepath = './tmp_cnn_v1/cnn_ckpt/model_{epoch:03d}_{val_loss:.4f}.h5'\n",
    "    # ckpt = ModelCheckpoint(ckpt_filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "        es = keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=300)\n",
    "        X_train=SurfaceTrain[train_id]\n",
    "        y_train=DUTrain[train_id]\n",
    "        X_val=SurfaceTrain[val_id]\n",
    "        y_val=DUTrain[val_id]\n",
    "        history = model.fit(X_train, y_train, epochs=2000,\n",
    "                        validation_data=(X_val, y_val),\n",
    "                        callbacks=[new_lr,es],verbose=0)\n",
    "        #print('---- training time for each evaluation %s seconds ----' % (time.time() - start_epoch))\n",
    "        \n",
    "        train_loss, val_mse = history.history['loss'], history.history['val_MAPE']\n",
    "        val_mse_k_fold[fold_num-1]=np.min(val_mse)\n",
    "        fold_num+=1\n",
    "    val_mse_mean=np.mean(val_mse_k_fold)\n",
    "    return np.min(val_mse_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3)   \n",
    "print(\"-----------Run BO to find the optimal hps------------\")\n",
    "result = gp_minimize(func=objective, dimensions=space, n_calls=60, acq_func='gp_hedge', n_restarts_optimizer=5,verbose=1)\n",
    "print(\"Best parameters: \", result.x)\n",
    "print(\"Minimum val loss: \", result.fun)\n",
    "    \n",
    "ToSave={\"n_neurons_0\":result.x[0],\"n_neurons_1\":result.x[1],\"n_neurons_2\":result.x[2],'activation':result.x[3],\"lr\":result.x[4],\"regularization\":result.x[5]}\n",
    "df=pd.DataFrame(ToSave,index=[0])\n",
    "df.to_csv('./Hyperparameters_kfold.csv',index=False,sep=';')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ToSave={\"n_neurons_0\":result.x[0],\"n_neurons_1\":result.x[1],\"n_neurons_2\":result.x[2],'activation':result.x[3],\"lr\":result.x[4],\"regularization\":result.x[5]}\n",
    "df=pd.DataFrame(ToSave,index=[0])\n",
    "df.to_csv('./Hyperparameters_BO.csv',index=False,sep=';')#Output hyperparameters in csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "val_loss_history=result.func_vals\n",
    "plt.plot(val_loss_history,color=[0,130/255,150/255],linewidth=3)\n",
    "plt.plot(np.argmin(val_loss_history),np.min(val_loss_history),'ro')\n",
    "plt.legend([\"BO\",\"selected\",\"Previous\"])\n",
    "plt.xlabel(\"BO iterations\")\n",
    "plt.ylabel(\"val_loss\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
